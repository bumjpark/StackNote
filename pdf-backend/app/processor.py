
import json
import os
import re
import time
import base64
from pathlib import Path
from typing import List, Dict, Any, Optional

import fitz  # PyMuPDF
from docling.document_converter import DocumentConverter

# ==========================================
# 1. Helper Functions (Geometry & Utils)
# ==========================================

def get_text_content(element) -> str:
    """Docling ìš”ì†Œì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    if hasattr(element, "text"):
        return element.text
    elif hasattr(element, "export_to_markdown"):
         try:
             return element.export_to_markdown()
         except:
             return ""
    return ""

def is_overlapping_with_images(text_bbox: List[float], image_bboxes: List[Dict], page_num: int, threshold: float = 0.5) -> bool:
    """
    í…ìŠ¤íŠ¸ BBoxê°€ ì´ë¯¸ì§€ BBoxì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (ì°Œêº¼ê¸° ì œê±°ìš©)
    threshold: ê²¹ì¹˜ëŠ” ë©´ì  ë¹„ìœ¨ (0.5 = 50% ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µ ê°„ì£¼)
    """
    if not text_bbox:
        return False
        
    tx1, ty1, tx2, ty2 = text_bbox
    # (Docling BBoxëŠ” [L, T, R, B] í˜•íƒœ)
    
    text_area = (tx2 - tx1) * (ty2 - ty1)
    if text_area <= 0:
        return False

    for img in image_bboxes:
        if img["page"] != page_num:
            continue
        
        ix1, iy1, ix2, iy2 = img["bbox"]
        
        # êµì°¨ ì˜ì—­ ê³„ì‚°
        x_left = max(tx1, ix1)
        y_top = max(ty1, iy1)
        x_right = min(tx2, ix2)
        y_bottom = min(ty2, iy2)
        
        if x_right > x_left and y_bottom > y_top:
            intersection_area = (x_right - x_left) * (y_bottom - y_top)
            if (intersection_area / text_area) > threshold:
                return True
                
    return False

# ==========================================
# 2. Main Processor Class
# ==========================================

class PDFProcessor:
    def __init__(self, upload_dir: str = "/app/uploads"):
        self.upload_dir = upload_dir
        self.converter = DocumentConverter() # Docling ì´ˆê¸°í™”
        
        # ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ìƒì„±
        os.makedirs(self.upload_dir, exist_ok=True)

    def process_pdf(self, pdf_path: str) -> Dict[str, Any]:
        """
        PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°(Elements)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        ìˆœì„œ: Docling ë¶„ì„ -> ì´ë¯¸ì§€/í‘œ BBox ì¶”ì¶œ -> PyMuPDF í¬ë¡­ -> í…ìŠ¤íŠ¸ í•„í„°ë§
        """
        start_time = time.time()
        print(f"ğŸš€ Processing PDF: {pdf_path}")
        
        # [Step 1] Docling Layout Analysis
        docling_result = self._run_docling(pdf_path)
        elements = docling_result["elements"]
        
        # [Step 1.5] Precision Layout Sorting (BBox ê¸°ë°˜ ì •ë ¬)
        # pdf_parsing/3.pyì˜ ë¡œì§ ì´ì‹: (í˜ì´ì§€, -ìƒë‹¨Y, ì¢Œì¸¡X) ìˆœìœ¼ë¡œ ì •ë ¬
        def sort_key(item):
            page = item["page"]
            bbox = item.get("bbox")
            if not bbox: return (page, 0, 0)
            # PDF ì¢Œí‘œê³„ëŠ” Bottom-Upì´ë¯€ë¡œ, ì‹œê°ì  ìƒë‹¨(Top)ì€ Yê°’ì´ í¼.
            # ë”°ë¼ì„œ -max(y1, y2)ë¥¼ í•˜ì—¬ ì‹œê°ì  ìœ„ìª½ì´ ë¨¼ì € ì˜¤ë„ë¡ í•¨.
            y_top = max(bbox[1], bbox[3])
            x_left = min(bbox[0], bbox[2])
            return (page, -y_top, x_left)

        elements.sort(key=sort_key)
        print(f"  ğŸ”„ Precision Sorting complete: sorted {len(elements)} elements")
        
        # [Step 2] ì´ë¯¸ì§€/í‘œ ìš”ì†Œ ì‹ë³„ ë° BBox ìˆ˜ì§‘
        image_elements = [e for e in elements if e["type"] in ["image", "table"] and e["bbox"]]
        image_bboxes = [{"page": e["page"], "bbox": e["bbox"]} for e in image_elements]
        
        # [Step 3] PyMuPDF Image Cropping
        # ì´ë¯¸ì§€ì™€ í‘œë¥¼ ê³ í™”ì§ˆë¡œ ì˜ë¼ë‚´ì–´ ì €ì¥í•˜ê³ , ì €ì¥ëœ ê²½ë¡œë¥¼ elementì— ì¶”ê°€í•©ë‹ˆë‹¤.
        self._crop_images(pdf_path, image_elements)
        
        # [Step 4] Filtering & Block Assembly
        final_blocks = []
        
        for e in elements:
            # 4-1. ì´ë¯¸ì§€/í‘œëŠ” ë¬´ì¡°ê±´ í¬í•¨ (ì´ë¯¸ ê²½ë¡œê°€ í• ë‹¹ë¨)
            if e["type"] in ["image", "table"]:
                # í¬ë¡­ì— ì‹¤íŒ¨í•˜ì—¬ image_pathê°€ ì—†ëŠ” ê²½ìš°ëŠ” ì œì™¸í•  ìˆ˜ë„ ìˆìŒ
                if e.get("image_path"): 
                    final_blocks.append(e)
                continue
                
            # 4-2. í…ìŠ¤íŠ¸ ìš”ì†Œ (Header, Paragraph ë“±)
            # ì´ë¯¸ì§€ ì˜ì—­ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸ (Overlap Check)
            if e.get("bbox") and is_overlapping_with_images(e["bbox"], image_bboxes, e["page"]):
                # ê²¹ì¹˜ë©´ 'ì°Œêº¼ê¸°'ë¡œ ê°„ì£¼í•˜ì—¬ Skip
                print(f"  ğŸ—‘ï¸ Skipped overlapping text (Page {e['page']}): {e['text'][:20]}...")
                continue
            
            # 4-3. ìœ íš¨í•œ í…ìŠ¤íŠ¸ë§Œ ì¶”ê°€
            if e.get("text") and len(e["text"].strip()) > 0:
                final_blocks.append(e)
                
        # [Step 5] ê²°ê³¼ ë°˜í™˜
        elapsed = time.time() - start_time
        return {
            "status": "success",
            "filename": os.path.basename(pdf_path),
            "total_pages": docling_result["total_pages"],
            "processed_time": f"{elapsed:.2f}s",
            "blocks": final_blocks
        }

    def _run_docling(self, pdf_path: str) -> Dict:
        """Docling ì‹¤í–‰ ë° JSON ë³€í™˜"""
        print("  Running Docling...")
        result = self.converter.convert(pdf_path)
        doc = result.document
        
        analyzed_elements = []
        
        type_mapping = {
            "SECTION_HEADER": "heading",    # BlockNote: heading
            "Title": "heading",
            "TEXT": "paragraph",            # BlockNote: paragraph
            "Body Text": "paragraph",
            "LIST_ITEM": "bulletListItem",  # BlockNote: bulletListItem (numberedëŠ” ë³„ë„ ì²˜ë¦¬ í•„ìš”í•˜ì§€ë§Œ ì¼ë‹¨ í†µì¼)
            "PICTURE": "image",             # BlockNote: image
            "FIGURE": "image",
            "TABLE": "table",               # Custom logic needed (imageë¡œ ì²˜ë¦¬ or table block)
            "CAPTION": "paragraph",         # ìº¡ì…˜ë„ í…ìŠ¤íŠ¸ë¡œ
            "CODE": "paragraph"             # ì½”ë“œë„ ì¼ë‹¨ í…ìŠ¤íŠ¸ë¡œ
        }
        
        last_page = 1
        for element, level in doc.iterate_items():
            # ìœ„ì¹˜ ì •ë³´ (BBox)
            bbox = None
            page_no = 1
            if hasattr(element, "prov") and element.prov:
                prov = element.prov[0]
                page_no = prov.page_no
                bbox = [prov.bbox.l, prov.bbox.t, prov.bbox.r, prov.bbox.b]
            
            # [í˜ì´ì§€ êµ¬ë¶„ì„ ] í˜ì´ì§€ ì „í™˜ ì‹œ divider ì‚½ì…
            if page_no > last_page:
                analyzed_elements.append({
                    "type": "divider",
                    "text": "",
                    "page": page_no,
                    "bbox": None,
                    "props": {}
                })
                last_page = page_no
            
            raw_type = element.label.name if hasattr(element, "label") else "unknown"
            final_type = type_mapping.get(raw_type, "paragraph") # ê¸°ë³¸ê°’ paragraph
            
            # Tableì€ ì´ë¯¸ì§€ë¡œ ì²˜ë¦¬í•˜ëŠ” ì „ëµ ("table" íƒ€ì… ìœ ì§€í•˜ë˜, ë‚˜ì¤‘ì— í¬ë¡­ë¨)
            text_content = get_text_content(element).strip()
            # ì—°ì†ëœ ê³µë°± ì œê±°
            text_content = re.sub(r'\s+', ' ', text_content)
            
            # [Bug Fix] í…ìŠ¤íŠ¸ê°€ ì—†ë”ë¼ë„ ì´ë¯¸ì§€ë‚˜ í‘œë¼ë©´ ê±´ë„ˆë›°ì§€ ì•ŠìŒ
            if not text_content and final_type not in ["image", "table"]:
                continue

            # ğŸŒŸ [í—¤ë” ê°ì§€ ê·¹ëŒ€í™”] í•µì‹¬ ì„¹ì…˜ ë° ì§§ì€ ì œëª©êµ° ê³µê²©ì  ë°°ì •
            is_strong_header = False
            
            # 1. ë¬¸ì„œ í•µì‹¬ ì„¹ì…˜ (Abstract, Intro ë“±) ë¬´ì¡°ê±´ í—¤ë”
            core_keywords = ["Abstract", "Introduction", "Related Work", "Methodology", "Experiments", "Results", "Discussion", "Conclusion", "References", "Acknowledgement"]
            core_keywords_ko = ["ì„œë¡ ", "ë³¸ë¡ ", "ê²°ë¡ ", "ìš”ì•½", "ì°¸ê³ ë¬¸í—Œ", "ì´ˆë¡", "ë°©ë²•ë¡ ", "ê²°ê³¼"]
            
            clean_text = text_content
            # í…ìŠ¤íŠ¸ê°€ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì¼ì¹˜í•˜ë©´ì„œ 30ì ë¯¸ë§Œì´ë©´ ê°•ë ¥í•œ í—¤ë”
            if any(clean_text.lower().startswith(kw.lower()) for kw in core_keywords + core_keywords_ko) and len(clean_text) < 40:
                is_strong_header = True
            
            # 2. ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì „í˜•ì ì¸ ì„¹ì…˜ ì œëª© íŒ¨í„´
            if final_type == "paragraph" and len(clean_text) < 60:
                if re.match(r'^(\d+(\.\d+)*[\.\s]|[IVXLC]+\.|\u25CF|\u25CB)', clean_text):
                    is_strong_header = True

            if is_strong_header:
                final_type = "heading"

            # ğŸŒŸ [ë¦¬ìŠ¤íŠ¸ ë° íƒ€ì… ì„¸ë°€í™”]
            if final_type == "bulletListItem" or (final_type == "paragraph" and clean_text.startswith(("- ", "* ", "\u2022 "))):
                if final_type == "paragraph":
                    final_type = "bulletListItem"
                    text_content = re.sub(r'^[\-\*\u2022]\s*', '', text_content)
                
                if re.match(r'^(\d+[\.\)]|[\u2460-\u2473])', clean_text):
                    final_type = "numberedListItem"

            # Heading Level ì²˜ë¦¬ (ì‹œê°ì  ìœ„ê³„ ê·¹ëŒ€í™”)
            props = {}
            if final_type == "heading":
                # íŒ¨í„´ ê¸°ë°˜ ë ˆë²¨ í• ë‹¹
                if re.match(r'^\d+\.?\s+[A-Zê°€-í£]', clean_text) or any(kw.lower() in clean_text.lower() for kw in core_keywords + core_keywords_ko):
                    props["level"] = 1 # ì„¹ì…˜ ëŒ€ì œëª© (H1)
                elif re.match(r'^\d+\.\d+', clean_text) or len(clean_text) < 15:
                    props["level"] = 2 # ì¤‘ë¶„ë¥˜ (H2)
                else:
                    props["level"] = 3 # ì†Œë¶„ë¥˜ (H3)
                
                # Docling level ë³´ì • (H1ì´ ë„ˆë¬´ ë§ì§€ ì•Šë„ë¡)
                if level is not None and level > 1:
                    props["level"] = min(level + 1, 3)

            # [í•„í„°ë§] ë…¸ì´ì¦ˆ ì œê±° (ìˆ«ìë§Œ ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ë…¸ì´ì¦ˆ)
            if final_type == "paragraph" and (len(clean_text) < 2 or clean_text.isdigit()):
                continue

            item = {
                "type": final_type,
                "text": text_content,
                "page": page_no,
                "bbox": bbox,
                "props": props
            }
            analyzed_elements.append(item)
            
        return {
            "total_pages": len(doc.pages),
            "elements": analyzed_elements
        }

    def _crop_images(self, pdf_path: str, image_elements: List[Dict]):
        """PyMuPDFë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€/í‘œ ì˜ì—­ í¬ë¡­"""
        print(f"  Cropping {len(image_elements)} images/tables...")
        
        if not image_elements:
            return

        doc = fitz.open(pdf_path)
        
        for i, item in enumerate(image_elements):
            if not item["bbox"]:
                continue
                
            page_num = item["page"]
            # PyMuPDFëŠ” 0-index
            if page_num - 1 >= len(doc): 
                continue
                
            page = doc[page_num - 1]
            page_h = page.rect.height
            
            l, t, r, b = item["bbox"]
            
            # Yì¶• ë°˜ì „ ë° ì¢Œí‘œ ë³€í™˜ (Docling -> PyMuPDF)
            # Docling: Bottom-Left Origin (PDF standard) usually, but check prov.
            # Assuming Docling returns coords as [L, T, R, B] where T < B in visual logic?
            # NO, Docling 'prov' uses PDF coordinates (Bottom-Up).
            # We need to flip Y.
            
            docling_top_y = max(t, b)     # PDFì¢Œí‘œê³„ì—ì„  í° ê°’ì´ ìœ„ìª½
            docling_bottom_y = min(t, b)  # PDFì¢Œí‘œê³„ì—ì„  ì‘ì€ ê°’ì´ ì•„ë˜ìª½
            
            new_top = page_h - docling_top_y
            new_bottom = page_h - docling_bottom_y
            
            # Rect ìƒì„±
            rect = fitz.Rect(l, new_top, r, new_bottom)
            rect = rect & page.rect # í´ë¨í•‘
            
            # [í•„í„°ë§ ë³µêµ¬] ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€(ë¡œê³ , ì¥ì‹ ë“±)ëŠ” ì›ë³¸ ì‚¬ì–‘ëŒ€ë¡œ ì œì™¸
            MIN_SIZE_PTS = 50 
            if rect.width < MIN_SIZE_PTS or rect.height < MIN_SIZE_PTS:
                print(f"  ğŸ—‘ï¸ [Skipped] Too small: {rect.width:.1f}x{rect.height:.1f} pts (Page {page_num})")
                continue

            # ë¹„ìœ¨ í•„í„° ë³µêµ¬ (ì„ , ìƒì í…Œë‘ë¦¬ ë“± ì¥ì‹ ìš”ì†Œ ì œì™¸)
            aspect_ratio = rect.width / rect.height
            if aspect_ratio > 30 or aspect_ratio < 0.03:
                print(f"  ğŸ—‘ï¸ [Skipped] Extreme aspect ratio: {aspect_ratio:.1f} (Page {page_num})")
                continue
                
            # ê³ í™”ì§ˆ ìº¡ì²˜
            zoom = 300 / 72 # 300 DPI
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat, clip=rect)
            
            # íŒŒì¼ ì €ì¥
            # hashë‚˜ timestampë¥¼ ì¨ì„œ ìœ ë‹ˆí¬í•˜ê²Œ ë§Œë“œëŠ”ê²Œ ì¢‹ìŒ
            timestamp = int(time.time() * 1000)
            filename = f"crop_{timestamp}_{i}.png"
            save_path = os.path.join(self.upload_dir, filename)
            
            pix.save(save_path)
            
            # ê²°ê³¼ì— ê²½ë¡œ(URL path) ì¶”ê°€
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì ‘ê·¼í•  ë•ŒëŠ” /uploads/filename í˜•íƒœê°€ ë¨
            # ì—¬ê¸°ì„œëŠ” íŒŒì¼ëª…ë§Œ ì €ì¥í•˜ê±°ë‚˜ ì›¹ ê²½ë¡œë¡œ ì €ì¥
            item["image_path"] = f"/uploads/{filename}"
            item["image_filename"] = filename
